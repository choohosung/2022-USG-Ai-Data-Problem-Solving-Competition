{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 library import\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "# Import xgboost library\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "seed_value=1050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "random.seed(seed_value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "np.random.seed(seed_value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "train_input = pd.read_csv('train_input.csv')\n",
    "test_input = pd.read_csv('test_input.csv')\n",
    "train_output = pd.read_csv('train_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 459)\n",
      "(1000, 1)\n",
      "(200, 459)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 형태 확인\n",
    "print(train_input.shape)\n",
    "print(train_output.shape)\n",
    "print(test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max absolute scaling\n",
    "mab = MaxAbsScaler()\n",
    "\n",
    "mab.fit(train_input)\n",
    "train_scale = mab.transform(train_input)\n",
    "\n",
    "mab.fit(test_input)\n",
    "test_scale = mab.transform(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust scaling\n",
    "ro = RobustScaler()\n",
    "\n",
    "ro.fit(train_scale)\n",
    "train_scale = ro.transform(train_scale)\n",
    "\n",
    "ro.fit(test_scale)\n",
    "test_scale = ro.transform(test_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>449</th>\n",
       "      <th>450</th>\n",
       "      <th>451</th>\n",
       "      <th>452</th>\n",
       "      <th>453</th>\n",
       "      <th>454</th>\n",
       "      <th>455</th>\n",
       "      <th>456</th>\n",
       "      <th>457</th>\n",
       "      <th>458</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.185512</td>\n",
       "      <td>-0.599641</td>\n",
       "      <td>-0.076349</td>\n",
       "      <td>-0.5625</td>\n",
       "      <td>-0.839321</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.578238</td>\n",
       "      <td>-0.138889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227731</td>\n",
       "      <td>-0.225605</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>-0.287850</td>\n",
       "      <td>2.410909</td>\n",
       "      <td>-0.161290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003554</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.200632</td>\n",
       "      <td>1.133771</td>\n",
       "      <td>-0.599641</td>\n",
       "      <td>-0.707746</td>\n",
       "      <td>-0.3125</td>\n",
       "      <td>0.704442</td>\n",
       "      <td>-0.849077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.872380</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227731</td>\n",
       "      <td>-0.225605</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.579439</td>\n",
       "      <td>-0.054545</td>\n",
       "      <td>-0.903226</td>\n",
       "      <td>1.250443</td>\n",
       "      <td>-0.332149</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.787758</td>\n",
       "      <td>-0.070130</td>\n",
       "      <td>-0.821404</td>\n",
       "      <td>-0.671505</td>\n",
       "      <td>2.1250</td>\n",
       "      <td>-0.286538</td>\n",
       "      <td>1.661624</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.520640</td>\n",
       "      <td>-0.388889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>1.309381</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.198131</td>\n",
       "      <td>-0.061818</td>\n",
       "      <td>-0.451613</td>\n",
       "      <td>0.746336</td>\n",
       "      <td>0.447819</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>0.441176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.642671</td>\n",
       "      <td>0.407010</td>\n",
       "      <td>-0.228460</td>\n",
       "      <td>-0.651537</td>\n",
       "      <td>-0.4375</td>\n",
       "      <td>-0.383630</td>\n",
       "      <td>-0.651261</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.956472</td>\n",
       "      <td>-0.694444</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298319</td>\n",
       "      <td>-0.067654</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-1.267290</td>\n",
       "      <td>-0.974545</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>-0.505771</td>\n",
       "      <td>-0.387399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.535247</td>\n",
       "      <td>-0.827291</td>\n",
       "      <td>0.665041</td>\n",
       "      <td>-0.6875</td>\n",
       "      <td>0.320027</td>\n",
       "      <td>0.059003</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.485727</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.505882</td>\n",
       "      <td>-0.262062</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.485981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.290323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.337964</td>\n",
       "      <td>7.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.411852</td>\n",
       "      <td>-0.381059</td>\n",
       "      <td>0.981245</td>\n",
       "      <td>0.531617</td>\n",
       "      <td>1.4375</td>\n",
       "      <td>-0.818552</td>\n",
       "      <td>-0.352988</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.570096</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.588235</td>\n",
       "      <td>0.221463</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.725234</td>\n",
       "      <td>-0.414545</td>\n",
       "      <td>3.935484</td>\n",
       "      <td>-0.609062</td>\n",
       "      <td>0.383845</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.511053</td>\n",
       "      <td>0.278644</td>\n",
       "      <td>-0.234455</td>\n",
       "      <td>-0.768341</td>\n",
       "      <td>-0.3750</td>\n",
       "      <td>0.898252</td>\n",
       "      <td>0.886639</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.843215</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.575630</td>\n",
       "      <td>1.160457</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>-0.725234</td>\n",
       "      <td>0.530909</td>\n",
       "      <td>1.580645</td>\n",
       "      <td>1.562785</td>\n",
       "      <td>-1.125363</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.939346</td>\n",
       "      <td>1.382876</td>\n",
       "      <td>0.409716</td>\n",
       "      <td>-0.749528</td>\n",
       "      <td>-0.7500</td>\n",
       "      <td>0.255913</td>\n",
       "      <td>1.170776</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.656988</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137815</td>\n",
       "      <td>0.185664</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.345794</td>\n",
       "      <td>-0.054545</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.745209</td>\n",
       "      <td>0.447819</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.558824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.010124</td>\n",
       "      <td>-0.344184</td>\n",
       "      <td>-0.368318</td>\n",
       "      <td>0.407831</td>\n",
       "      <td>-0.6250</td>\n",
       "      <td>-0.565470</td>\n",
       "      <td>1.137741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.692960</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.791597</td>\n",
       "      <td>0.319773</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.183178</td>\n",
       "      <td>-0.309091</td>\n",
       "      <td>-0.258065</td>\n",
       "      <td>1.527245</td>\n",
       "      <td>0.834572</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 459 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3       4         5         6    7    \\\n",
       "0       NaN  1.185512 -0.599641 -0.076349 -0.5625 -0.839321  0.000476  0.0   \n",
       "1  1.200632  1.133771 -0.599641 -0.707746 -0.3125  0.704442 -0.849077  0.0   \n",
       "2  0.787758 -0.070130 -0.821404 -0.671505  2.1250 -0.286538  1.661624  0.5   \n",
       "3 -0.642671  0.407010 -0.228460 -0.651537 -0.4375 -0.383630 -0.651261 -0.5   \n",
       "4       NaN  0.535247 -0.827291  0.665041 -0.6875  0.320027  0.059003  0.5   \n",
       "5 -0.411852 -0.381059  0.981245  0.531617  1.4375 -0.818552 -0.352988  0.5   \n",
       "6  1.511053  0.278644 -0.234455 -0.768341 -0.3750  0.898252  0.886639 -0.5   \n",
       "7  0.939346  1.382876  0.409716 -0.749528 -0.7500  0.255913  1.170776 -1.0   \n",
       "8  1.010124 -0.344184 -0.368318  0.407831 -0.6250 -0.565470  1.137741  0.0   \n",
       "\n",
       "        8         9    ...       449       450       451       452       453  \\\n",
       "0 -0.578238 -0.138889  ...  0.227731 -0.225605  1.166667 -0.287850  2.410909   \n",
       "1  0.872380  0.083333  ...  0.227731 -0.225605  0.333333 -0.579439 -0.054545   \n",
       "2  0.520640 -0.388889  ...  0.764706  1.309381  0.166667 -0.198131 -0.061818   \n",
       "3  0.956472 -0.694444  ... -0.298319 -0.067654 -0.333333 -1.267290 -0.974545   \n",
       "4 -0.485727  0.611111  ... -0.505882 -0.262062 -1.000000  0.485981       NaN   \n",
       "5  0.570096  0.194444  ... -0.588235  0.221463 -0.666667 -0.725234 -0.414545   \n",
       "6  0.843215 -1.333333  ... -0.575630  1.160457  1.833333 -0.725234  0.530909   \n",
       "7  0.656988  1.250000  ...  0.137815  0.185664  0.333333  1.345794 -0.054545   \n",
       "8  0.692960  0.444444  ... -0.791597  0.319773 -0.166667  0.183178 -0.309091   \n",
       "\n",
       "        454       455       456  457       458  \n",
       "0 -0.161290       NaN  0.003554 -0.2  0.617647  \n",
       "1 -0.903226  1.250443 -0.332149 -0.4  0.676471  \n",
       "2 -0.451613  0.746336  0.447819 -1.2  0.441176  \n",
       "3  0.419355 -0.505771 -0.387399  0.0       NaN  \n",
       "4 -0.290323       NaN -0.337964  7.2       NaN  \n",
       "5  3.935484 -0.609062  0.383845  0.2       NaN  \n",
       "6  1.580645  1.562785 -1.125363  0.6       NaN  \n",
       "7  0.870968  0.745209  0.447819 -0.8  0.558824  \n",
       "8 -0.258065  1.527245  0.834572  0.4       NaN  \n",
       "\n",
       "[9 rows x 459 columns]"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scale_pd = pd.DataFrame(train_scale)\n",
    "train_scale_pd.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameter 조정\n",
    "model = XGBClassifier(booster='gblinear', random_state=seed_value, learning_rate=0.005, n_estimators=1050, objective='binary:hinge',\n",
    "                     reg_lambda=0, base_score=0, importance_type='gain',  use_label_encoder=False, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0, booster='gblinear', colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "              gpu_id=-1, importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.005, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=1050, n_jobs=-1, num_parallel_tree=None,\n",
       "              objective='binary:hinge', random_state=1050, reg_alpha=0,\n",
       "              reg_lambda=0, scale_pos_weight=None, subsample=None,\n",
       "              tree_method=None, use_label_encoder=False, validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model fitting\n",
    "model.fit(train_scale, train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 예측\n",
    "y_pred = model.predict(test_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측결과\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle로 학습된 모델 저장\n",
    "import pickle\n",
    "file_name = \"xgb_reg.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "pickle.dump(model, open(file_name, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "xgb_model_loaded = pickle.load(open(file_name, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "test = test_scale\n",
    "xgb_model_loaded.predict(test)[0] == model.predict(test)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
